# Configuration file for trace generation
# You can override these values via command-line arguments

# Model and dataset configuration
model_name: "Qwen/Qwen3-4B"  # Path or HuggingFace model ID

# Generation parameters
temperature: 0.7
max_tokens: 8192
top_p: 0.9
seed: 42
prompt_variant: "prompt_remove_answer"  

# vLLM configuration
vllm_kwargs:
  dtype: "auto"  # auto, float16, bfloat16, float32
  trust_remote_code: false
  max_model_len: null  # null = auto
  max_num_batched_tokens: null  # null = auto
  tensor_parallel_size: null  # null = auto-detect from available GPUs
  max_num_seqs: 32
  gpu_memory_utilization: 0.7
